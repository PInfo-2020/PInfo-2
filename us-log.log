4f3fbef97483
832dc36b1909
e2b77d52e3ed
3140f1ddf40b
4f3fbef97483
832dc36b1909
e2b77d52e3ed
3140f1ddf40b
docker-compose_pgdata-usr
Creating volume "docker-compose_pgdata-usr" with default driver
Creating zookeeper ... 
Creating user-database ... 
[1A[2KCreating user-database ... [32mdone[0m[1B[2A[2KCreating zookeeper     ... [32mdone[0m[2BCreating kafka         ... 
[1A[2KCreating kafka         ... [32mdone[0m[1BCreating user-service  ... 
[1A[2KCreating user-service  ... [32mdone[0m[1BAttaching to user-database, zookeeper, kafka, user-service
[36mkafka            |[0m ===> ENV Variables ...
[36mkafka            |[0m ALLOW_UNSIGNED=false
[36mkafka            |[0m COMPONENT=kafka
[36mkafka            |[0m CONFLUENT_DEB_VERSION=1
[36mkafka            |[0m CONFLUENT_MAJOR_VERSION=5
[36mkafka            |[0m CONFLUENT_MINOR_VERSION=1
[36mkafka            |[0m CONFLUENT_MVN_LABEL=
[36mkafka            |[0m CONFLUENT_PATCH_VERSION=0
[36mkafka            |[0m CONFLUENT_PLATFORM_LABEL=
[36mkafka            |[0m CONFLUENT_VERSION=5.1.0
[36mkafka            |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[36mkafka            |[0m HOME=/root
[36mkafka            |[0m HOSTNAME=kafka
[36mkafka            |[0m KAFKA_ADVERTISED_LISTENERS=LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://kafka:9092
[36mkafka            |[0m KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
[36mkafka            |[0m KAFKA_BROKER_ID=1
[36mkafka            |[0m KAFKA_INTER_BROKER_LISTENER_NAME=LISTENER_DOCKER_INTERNAL
[36mkafka            |[0m KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
[36mkafka            |[0m KAFKA_LOG4J_LOGGERS=kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO
[36mkafka            |[0m KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
[36mkafka            |[0m KAFKA_VERSION=2.1.0
[36mkafka            |[0m KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
[36mkafka            |[0m LANG=C.UTF-8
[36mkafka            |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36mkafka            |[0m PWD=/
[36mkafka            |[0m PYTHON_PIP_VERSION=8.1.2
[36mkafka            |[0m PYTHON_VERSION=2.7.9-1
[36mkafka            |[0m SCALA_VERSION=2.11
[36mkafka            |[0m SHLVL=1
[36mkafka            |[0m ZULU_OPENJDK_VERSION=8=8.30.0.1
[36mkafka            |[0m _=/usr/bin/env
[36mkafka            |[0m ===> User
[36mkafka            |[0m uid=0(root) gid=0(root) groups=0(root)
[36mkafka            |[0m ===> Configuring ...
[33muser-database    |[0m The files belonging to this database system will be owned by user "postgres".
[33muser-database    |[0m This user must also own the server process.
[33muser-database    |[0m 
[33muser-database    |[0m The database cluster will be initialized with locale "en_US.utf8".
[33muser-database    |[0m The default database encoding has accordingly been set to "UTF8".
[33muser-database    |[0m The default text search configuration will be set to "english".
[33muser-database    |[0m 
[33muser-database    |[0m Data page checksums are disabled.
[33muser-database    |[0m 
[33muser-database    |[0m fixing permissions on existing directory /var/lib/postgresql/data ... ok
[33muser-database    |[0m creating subdirectories ... ok
[33muser-database    |[0m selecting default max_connections ... 100
[33muser-database    |[0m selecting default shared_buffers ... 128MB
[33muser-database    |[0m selecting default timezone ... Etc/UTC
[33muser-database    |[0m selecting dynamic shared memory implementation ... posix
[33muser-database    |[0m creating configuration files ... ok
[33muser-database    |[0m running bootstrap script ... ok
[33muser-database    |[0m performing post-bootstrap initialization ... ok
[33muser-database    |[0m syncing data to disk ... ok
[33muser-database    |[0m 
[33muser-database    |[0m WARNING: enabling "trust" authentication for local connections
[33muser-database    |[0m You can change this by editing pg_hba.conf or using the option -A, or
[33muser-database    |[0m --auth-local and --auth-host, the next time you run initdb.
[33muser-database    |[0m 
[33muser-database    |[0m Success. You can now start the database server using:
[33muser-database    |[0m 
[33muser-database    |[0m     pg_ctl -D /var/lib/postgresql/data -l logfile start
[33muser-database    |[0m 
[33muser-database    |[0m waiting for server to start....2020-06-02 10:38:53.465 UTC [46] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[33muser-database    |[0m 2020-06-02 10:38:53.487 UTC [47] LOG:  database system was shut down at 2020-06-02 10:38:52 UTC
[33muser-database    |[0m 2020-06-02 10:38:53.494 UTC [46] LOG:  database system is ready to accept connections
[33muser-database    |[0m  done
[33muser-database    |[0m server started
[35mzookeeper        |[0m ZooKeeper JMX enabled by default
[35mzookeeper        |[0m Using config: /conf/zoo.cfg
[35mzookeeper        |[0m 2020-06-02 10:38:52,277 [myid:] - INFO  [main:QuorumPeerConfig@124] - Reading configuration from: /conf/zoo.cfg
[35mzookeeper        |[0m 2020-06-02 10:38:52,348 [myid:] - INFO  [main:QuorumPeer$QuorumServer@149] - Resolved hostname: zookeeper to address: zookeeper/172.22.0.3
[35mzookeeper        |[0m 2020-06-02 10:38:52,349 [myid:] - ERROR [main:QuorumPeerConfig@301] - Invalid configuration, only one server specified (ignoring)
[35mzookeeper        |[0m 2020-06-02 10:38:52,361 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[35mzookeeper        |[0m 2020-06-02 10:38:52,361 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
[35mzookeeper        |[0m 2020-06-02 10:38:52,365 [myid:] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
[35mzookeeper        |[0m 2020-06-02 10:38:52,366 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
[35mzookeeper        |[0m 2020-06-02 10:38:52,400 [myid:] - INFO  [main:QuorumPeerConfig@124] - Reading configuration from: /conf/zoo.cfg
[35mzookeeper        |[0m 2020-06-02 10:38:52,401 [myid:] - INFO  [main:QuorumPeer$QuorumServer@149] - Resolved hostname: zookeeper to address: zookeeper/172.22.0.3
[35mzookeeper        |[0m 2020-06-02 10:38:52,401 [myid:] - ERROR [main:QuorumPeerConfig@301] - Invalid configuration, only one server specified (ignoring)
[35mzookeeper        |[0m 2020-06-02 10:38:52,401 [myid:] - INFO  [main:ZooKeeperServerMain@96] - Starting server
[35mzookeeper        |[0m 2020-06-02 10:38:52,412 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
[35mzookeeper        |[0m 2020-06-02 10:38:52,413 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=zookeeper
[35mzookeeper        |[0m 2020-06-02 10:38:52,413 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.8.0_121
[35mzookeeper        |[0m 2020-06-02 10:38:52,416 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[35mzookeeper        |[0m 2020-06-02 10:38:52,417 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-1.8-openjdk/jre
[35mzookeeper        |[0m 2020-06-02 10:38:52,421 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/zookeeper-3.4.9/bin/../build/classes:/zookeeper-3.4.9/bin/../build/lib/*.jar:/zookeeper-3.4.9/bin/../lib/slf4j-log4j12-1.6.1.jar:/zookeeper-3.4.9/bin/../lib/slf4j-api-1.6.1.jar:/zookeeper-3.4.9/bin/../lib/netty-3.10.5.Final.jar:/zookeeper-3.4.9/bin/../lib/log4j-1.2.16.jar:/zookeeper-3.4.9/bin/../lib/jline-0.9.94.jar:/zookeeper-3.4.9/bin/../zookeeper-3.4.9.jar:/zookeeper-3.4.9/bin/../src/java/lib/*.jar:/conf:
[35mzookeeper        |[0m 2020-06-02 10:38:52,422 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[35mzookeeper        |[0m 2020-06-02 10:38:52,422 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[35mzookeeper        |[0m 2020-06-02 10:38:52,423 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[35mzookeeper        |[0m 2020-06-02 10:38:52,423 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[35mzookeeper        |[0m 2020-06-02 10:38:52,424 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[35mzookeeper        |[0m 2020-06-02 10:38:52,424 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.4.0-33-generic
[35mzookeeper        |[0m 2020-06-02 10:38:52,425 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=zookeeper
[35mzookeeper        |[0m 2020-06-02 10:38:52,426 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/home/zookeeper
[35mzookeeper        |[0m 2020-06-02 10:38:52,426 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/zookeeper-3.4.9
[35mzookeeper        |[0m 2020-06-02 10:38:52,439 [myid:] - INFO  [main:ZooKeeperServer@815] - tickTime set to 2000
[35mzookeeper        |[0m 2020-06-02 10:38:52,440 [myid:] - INFO  [main:ZooKeeperServer@824] - minSessionTimeout set to -1
[35mzookeeper        |[0m 2020-06-02 10:38:52,440 [myid:] - INFO  [main:ZooKeeperServer@833] - maxSessionTimeout set to -1
[35mzookeeper        |[0m 2020-06-02 10:38:52,473 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33muser-database    |[0m CREATE DATABASE
[33muser-database    |[0m 
[33muser-database    |[0m 
[33muser-database    |[0m /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init.sql
[33muser-database    |[0m psql:/docker-entrypoint-initdb.d/init.sql:2: NOTICE:  table "auser" does not exist, skipping
[33muser-database    |[0m DROP TABLE
[33muser-database    |[0m psql:/docker-entrypoint-initdb.d/init.sql:3: NOTICE:  sequence "user_seq" does not exist, skipping
[33muser-database    |[0m DROP SEQUENCE
[33muser-database    |[0m CREATE SEQUENCE
[33muser-database    |[0m CREATE TABLE
[33muser-database    |[0m GRANT
[33muser-database    |[0m GRANT
[33muser-database    |[0m TRUNCATE TABLE
[33muser-database    |[0m INSERT 0 1
[33muser-database    |[0m INSERT 0 1
[33muser-database    |[0m 
[33muser-database    |[0m 
[33muser-database    |[0m 2020-06-02 10:38:54.181 UTC [46] LOG:  received fast shutdown request
[33muser-database    |[0m waiting for server to shut down....2020-06-02 10:38:54.183 UTC [46] LOG:  aborting any active transactions
[33muser-database    |[0m 2020-06-02 10:38:54.186 UTC [46] LOG:  worker process: logical replication launcher (PID 53) exited with exit code 1
[33muser-database    |[0m 2020-06-02 10:38:54.187 UTC [48] LOG:  shutting down
[33muser-database    |[0m 2020-06-02 10:38:54.229 UTC [46] LOG:  database system is shut down
[33muser-database    |[0m  done
[33muser-database    |[0m server stopped
[33muser-database    |[0m 
[33muser-database    |[0m PostgreSQL init process complete; ready for start up.
[33muser-database    |[0m 
[33muser-database    |[0m 2020-06-02 10:38:54.314 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[33muser-database    |[0m 2020-06-02 10:38:54.314 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[33muser-database    |[0m 2020-06-02 10:38:54.320 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[33muser-database    |[0m 2020-06-02 10:38:54.343 UTC [73] LOG:  database system was shut down at 2020-06-02 10:38:54 UTC
[33muser-database    |[0m 2020-06-02 10:38:54.350 UTC [1] LOG:  database system is ready to accept connections
[36mkafka            |[0m ===> Running preflight checks ... 
[36mkafka            |[0m ===> Check if /var/lib/kafka/data is writable ...
[36mkafka            |[0m ===> Check if Zookeeper is healthy ...
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:host.name=kafka
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_172
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Azul Systems, Inc.
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.version=5.4.0-33-generic
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.name=root
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.home=/root
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@b1bc7ed
[36mkafka            |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server zookeeper/172.22.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
[36mkafka            |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to zookeeper/172.22.0.3:2181, initiating session
[35mzookeeper        |[0m 2020-06-02 10:39:01,305 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /172.22.0.4:33776
[35mzookeeper        |[0m 2020-06-02 10:39:01,314 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@928] - Client attempting to establish new session at /172.22.0.4:33776
[35mzookeeper        |[0m 2020-06-02 10:39:01,316 [myid:] - INFO  [SyncThread:0:FileTxnLog@203] - Creating new log file: log.4db
[35mzookeeper        |[0m 2020-06-02 10:39:01,326 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@673] - Established session 0x172749ccd300000 with negotiated timeout 40000 for client /172.22.0.4:33776
[36mkafka            |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server zookeeper/172.22.0.3:2181, sessionid = 0x172749ccd300000, negotiated timeout = 40000
[35mzookeeper        |[0m 2020-06-02 10:39:01,337 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x172749ccd300000
[36mkafka            |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Session: 0x172749ccd300000 closed
[35mzookeeper        |[0m 2020-06-02 10:39:01,341 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1008] - Closed socket connection for client /172.22.0.4:33776 which had sessionid 0x172749ccd300000
[36mkafka            |[0m ===> Launching ... 
[36mkafka            |[0m ===> Launching kafka ... 
[32muser-service     |[0m [0m2020-06-02 10:39:02,231 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                   JAX-RS - STABLE          io.thorntail:jaxrs:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,262 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                  Logging - STABLE          io.thorntail:logging:2.6.0.Final
[32muser-service     |[0m [0m[33m2020-06-02 10:39:02,263 WARN  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                  Swagger - UNSTABLE        io.thorntail:swagger:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,263 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:        CDI Configuration - STABLE          io.thorntail:cdi-config:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,264 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                 Undertow - STABLE          io.thorntail:undertow:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,264 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                 Remoting - STABLE          io.thorntail:remoting:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,265 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                      JMX - STABLE          io.thorntail:jmx:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,271 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:               Infinispan - STABLE          io.thorntail:infinispan:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,271 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:             Transactions - STABLE          io.thorntail:transactions:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,273 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                      CDI - STABLE          io.thorntail:cdi:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,273 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                      JCA - STABLE          io.thorntail:jca:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,274 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                      JPA - STABLE          io.thorntail:jpa:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,274 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:                  Elytron - STABLE          io.thorntail:elytron:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,275 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:              Datasources - STABLE          io.thorntail:datasources:2.6.0.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:02,275 INFO  [org.wildfly.swarm] (main) THORN0013: Installed fraction:          Bean Validation - STABLE          io.thorntail:bean-validation:2.6.0.Final
[36mkafka            |[0m [2020-06-02 10:39:02,474] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[36mkafka            |[0m [2020-06-02 10:39:02,962] INFO KafkaConfig values: 
[36mkafka            |[0m 	advertised.host.name = null
[36mkafka            |[0m 	advertised.listeners = LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://kafka:9092
[36mkafka            |[0m 	advertised.port = null
[36mkafka            |[0m 	alter.config.policy.class.name = null
[36mkafka            |[0m 	alter.log.dirs.replication.quota.window.num = 11
[36mkafka            |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[36mkafka            |[0m 	authorizer.class.name = 
[36mkafka            |[0m 	auto.create.topics.enable = true
[36mkafka            |[0m 	auto.leader.rebalance.enable = true
[36mkafka            |[0m 	background.threads = 10
[36mkafka            |[0m 	broker.id = 1
[36mkafka            |[0m 	broker.id.generation.enable = true
[36mkafka            |[0m 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
[36mkafka            |[0m 	broker.rack = null
[36mkafka            |[0m 	client.quota.callback.class = null
[36mkafka            |[0m 	compression.type = producer
[36mkafka            |[0m 	connection.failed.authentication.delay.ms = 100
[36mkafka            |[0m 	connections.max.idle.ms = 600000
[36mkafka            |[0m 	controlled.shutdown.enable = true
[36mkafka            |[0m 	controlled.shutdown.max.retries = 3
[36mkafka            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mkafka            |[0m 	controller.socket.timeout.ms = 30000
[36mkafka            |[0m 	create.topic.policy.class.name = null
[36mkafka            |[0m 	default.replication.factor = 1
[36mkafka            |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[36mkafka            |[0m 	delegation.token.expiry.time.ms = 86400000
[36mkafka            |[0m 	delegation.token.master.key = null
[36mkafka            |[0m 	delegation.token.max.lifetime.ms = 604800000
[36mkafka            |[0m 	delete.records.purgatory.purge.interval.requests = 1
[36mkafka            |[0m 	delete.topic.enable = true
[36mkafka            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mkafka            |[0m 	group.initial.rebalance.delay.ms = 3000
[36mkafka            |[0m 	group.max.session.timeout.ms = 300000
[36mkafka            |[0m 	group.min.session.timeout.ms = 6000
[36mkafka            |[0m 	host.name = 
[36mkafka            |[0m 	inter.broker.listener.name = LISTENER_DOCKER_INTERNAL
[36mkafka            |[0m 	inter.broker.protocol.version = 2.1-IV2
[36mkafka            |[0m 	kafka.metrics.polling.interval.secs = 10
[36mkafka            |[0m 	kafka.metrics.reporters = []
[36mkafka            |[0m 	leader.imbalance.check.interval.seconds = 300
[36mkafka            |[0m 	leader.imbalance.per.broker.percentage = 10
[36mkafka            |[0m 	listener.security.protocol.map = LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
[36mkafka            |[0m 	listeners = LISTENER_DOCKER_INTERNAL://0.0.0.0:19092,LISTENER_DOCKER_EXTERNAL://0.0.0.0:9092
[36mkafka            |[0m 	log.cleaner.backoff.ms = 15000
[36mkafka            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mkafka            |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mkafka            |[0m 	log.cleaner.enable = true
[36mkafka            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mkafka            |[0m 	log.cleaner.io.buffer.size = 524288
[36mkafka            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mkafka            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mkafka            |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36mkafka            |[0m 	log.cleaner.threads = 1
[36mkafka            |[0m 	log.cleanup.policy = [delete]
[36mkafka            |[0m 	log.dir = /tmp/kafka-logs
[36mkafka            |[0m 	log.dirs = /var/lib/kafka/data
[36mkafka            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mkafka            |[0m 	log.flush.interval.ms = null
[36mkafka            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mkafka            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mkafka            |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[36mkafka            |[0m 	log.index.interval.bytes = 4096
[36mkafka            |[0m 	log.index.size.max.bytes = 10485760
[36mkafka            |[0m 	log.message.downconversion.enable = true
[36mkafka            |[0m 	log.message.format.version = 2.1-IV2
[36mkafka            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mkafka            |[0m 	log.message.timestamp.type = CreateTime
[36mkafka            |[0m 	log.preallocate = false
[36mkafka            |[0m 	log.retention.bytes = -1
[36mkafka            |[0m 	log.retention.check.interval.ms = 300000
[36mkafka            |[0m 	log.retention.hours = 168
[36mkafka            |[0m 	log.retention.minutes = null
[36mkafka            |[0m 	log.retention.ms = null
[36mkafka            |[0m 	log.roll.hours = 168
[36mkafka            |[0m 	log.roll.jitter.hours = 0
[36mkafka            |[0m 	log.roll.jitter.ms = null
[36mkafka            |[0m 	log.roll.ms = null
[36mkafka            |[0m 	log.segment.bytes = 1073741824
[36mkafka            |[0m 	log.segment.delete.delay.ms = 60000
[36mkafka            |[0m 	max.connections.per.ip = 2147483647
[36mkafka            |[0m 	max.connections.per.ip.overrides = 
[36mkafka            |[0m 	max.incremental.fetch.session.cache.slots = 1000
[36mkafka            |[0m 	message.max.bytes = 1000012
[36mkafka            |[0m 	metric.reporters = []
[36mkafka            |[0m 	metrics.num.samples = 2
[36mkafka            |[0m 	metrics.recording.level = INFO
[36mkafka            |[0m 	metrics.sample.window.ms = 30000
[36mkafka            |[0m 	min.insync.replicas = 1
[36mkafka            |[0m 	num.io.threads = 8
[36mkafka            |[0m 	num.network.threads = 3
[36mkafka            |[0m 	num.partitions = 1
[36mkafka            |[0m 	num.recovery.threads.per.data.dir = 1
[36mkafka            |[0m 	num.replica.alter.log.dirs.threads = null
[36mkafka            |[0m 	num.replica.fetchers = 1
[36mkafka            |[0m 	offset.metadata.max.bytes = 4096
[36mkafka            |[0m 	offsets.commit.required.acks = -1
[36mkafka            |[0m 	offsets.commit.timeout.ms = 5000
[36mkafka            |[0m 	offsets.load.buffer.size = 5242880
[36mkafka            |[0m 	offsets.retention.check.interval.ms = 600000
[36mkafka            |[0m 	offsets.retention.minutes = 10080
[36mkafka            |[0m 	offsets.topic.compression.codec = 0
[36mkafka            |[0m 	offsets.topic.num.partitions = 50
[36mkafka            |[0m 	offsets.topic.replication.factor = 1
[36mkafka            |[0m 	offsets.topic.segment.bytes = 104857600
[36mkafka            |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36mkafka            |[0m 	password.encoder.iterations = 4096
[36mkafka            |[0m 	password.encoder.key.length = 128
[36mkafka            |[0m 	password.encoder.keyfactory.algorithm = null
[36mkafka            |[0m 	password.encoder.old.secret = null
[36mkafka            |[0m 	password.encoder.secret = null
[36mkafka            |[0m 	port = 9092
[36mkafka            |[0m 	principal.builder.class = null
[36mkafka            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mkafka            |[0m 	queued.max.request.bytes = -1
[36mkafka            |[0m 	queued.max.requests = 500
[36mkafka            |[0m 	quota.consumer.default = 9223372036854775807
[36mkafka            |[0m 	quota.producer.default = 9223372036854775807
[36mkafka            |[0m 	quota.window.num = 11
[36mkafka            |[0m 	quota.window.size.seconds = 1
[36mkafka            |[0m 	replica.fetch.backoff.ms = 1000
[36mkafka            |[0m 	replica.fetch.max.bytes = 1048576
[36mkafka            |[0m 	replica.fetch.min.bytes = 1
[36mkafka            |[0m 	replica.fetch.response.max.bytes = 10485760
[36mkafka            |[0m 	replica.fetch.wait.max.ms = 500
[36mkafka            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mkafka            |[0m 	replica.lag.time.max.ms = 10000
[36mkafka            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mkafka            |[0m 	replica.socket.timeout.ms = 30000
[36mkafka            |[0m 	replication.quota.window.num = 11
[36mkafka            |[0m 	replication.quota.window.size.seconds = 1
[36mkafka            |[0m 	request.timeout.ms = 30000
[36mkafka            |[0m 	reserved.broker.max.id = 1000
[36mkafka            |[0m 	sasl.client.callback.handler.class = null
[36mkafka            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mkafka            |[0m 	sasl.jaas.config = null
[36mkafka            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkafka            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mkafka            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mkafka            |[0m 	sasl.kerberos.service.name = null
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.callback.handler.class = null
[36mkafka            |[0m 	sasl.login.class = null
[36mkafka            |[0m 	sasl.login.refresh.buffer.seconds = 300
[36mkafka            |[0m 	sasl.login.refresh.min.period.seconds = 60
[36mkafka            |[0m 	sasl.login.refresh.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.refresh.window.jitter = 0.05
[36mkafka            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mkafka            |[0m 	sasl.server.callback.handler.class = null
[36mkafka            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mkafka            |[0m 	socket.receive.buffer.bytes = 102400
[36mkafka            |[0m 	socket.request.max.bytes = 104857600
[36mkafka            |[0m 	socket.send.buffer.bytes = 102400
[36mkafka            |[0m 	ssl.cipher.suites = []
[36mkafka            |[0m 	ssl.client.auth = none
[36mkafka            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mkafka            |[0m 	ssl.endpoint.identification.algorithm = https
[36mkafka            |[0m 	ssl.key.password = null
[36mkafka            |[0m 	ssl.keymanager.algorithm = SunX509
[36mkafka            |[0m 	ssl.keystore.location = null
[36mkafka            |[0m 	ssl.keystore.password = null
[36mkafka            |[0m 	ssl.keystore.type = JKS
[36mkafka            |[0m 	ssl.protocol = TLS
[36mkafka            |[0m 	ssl.provider = null
[36mkafka            |[0m 	ssl.secure.random.implementation = null
[36mkafka            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mkafka            |[0m 	ssl.truststore.location = null
[36mkafka            |[0m 	ssl.truststore.password = null
[36mkafka            |[0m 	ssl.truststore.type = JKS
[36mkafka            |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[36mkafka            |[0m 	transaction.max.timeout.ms = 900000
[36mkafka            |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[36mkafka            |[0m 	transaction.state.log.load.buffer.size = 5242880
[36mkafka            |[0m 	transaction.state.log.min.isr = 2
[36mkafka            |[0m 	transaction.state.log.num.partitions = 50
[36mkafka            |[0m 	transaction.state.log.replication.factor = 3
[36mkafka            |[0m 	transaction.state.log.segment.bytes = 104857600
[36mkafka            |[0m 	transactional.id.expiration.ms = 604800000
[36mkafka            |[0m 	unclean.leader.election.enable = false
[36mkafka            |[0m 	zookeeper.connect = zookeeper:2181
[36mkafka            |[0m 	zookeeper.connection.timeout.ms = null
[36mkafka            |[0m 	zookeeper.max.in.flight.requests = 10
[36mkafka            |[0m 	zookeeper.session.timeout.ms = 6000
[36mkafka            |[0m 	zookeeper.set.acl = false
[36mkafka            |[0m 	zookeeper.sync.time.ms = 2000
[36mkafka            |[0m  (kafka.server.KafkaConfig)
[36mkafka            |[0m [2020-06-02 10:39:03,087] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[36mkafka            |[0m [2020-06-02 10:39:03,157] WARN Please note that the support metrics collection feature ("Metrics") of Proactive Support is enabled.  With Metrics enabled, this broker is configured to collect and report certain broker and cluster metadata ("Metadata") about your use of the Confluent Platform (including without limitation, your remote internet protocol address) to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every 24hours.  This Metadata may be transferred to any country in which Confluent maintains facilities.  For a more in depth discussion of how Confluent processes such information, please read our Privacy Policy located at http://www.confluent.io/privacy. By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer, storage and use of Metadata by Confluent.  You can turn the Metrics feature off by setting `confluent.support.metrics.enable=false` in the broker configuration and restarting the broker.  See the Confluent Platform documentation for further information. (io.confluent.support.metrics.SupportedServerStartable)
[36mkafka            |[0m [2020-06-02 10:39:03,167] INFO starting (kafka.server.KafkaServer)
[36mkafka            |[0m [2020-06-02 10:39:03,168] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[36mkafka            |[0m [2020-06-02 10:39:03,201] INFO [ZooKeeperClient] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[36mkafka            |[0m [2020-06-02 10:39:03,209] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,209] INFO Client environment:host.name=kafka (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,209] INFO Client environment:java.version=1.8.0_172 (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,209] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,209] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,209] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/scala-logging_2.11-3.9.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.1.0-cp1-test.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.13.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.7.jar:/usr/bin/../share/java/kafka/zstd-jni-1.3.5-4.jar:/usr/bin/../share/java/kafka/connect-json-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/maven-artifact-3.5.4.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.1.0.jar:/usr/bin/../share/java/kafka/scala-reflect-2.11.12.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0-b42.jar:/usr/bin/../share/java/kafka/httpmime-4.5.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-tools-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/javax.inject-2.5.0-b42.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.7.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/scala-library-2.11.12.jar:/usr/bin/../share/java/kafka/jersey-server-2.27.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/commons-lang3-3.5.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.27.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/httpcore-4.4.4.jar:/usr/bin/../share/java/kafka/connect-runtime-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.27.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.27.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.1.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.25.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/lz4-java-1.5.0.jar:/usr/bin/../share/java/kafka/kafka-streams-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.1.0.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.7.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.27.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.7.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.25.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.11-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0-b42.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.7.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0-b42.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.2.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/zkclient-0.10.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/connect-file-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/jline-0.9.94.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.1.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.7.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/connect-api-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.27.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/plexus-utils-3.1.0.jar:/usr/bin/../share/java/kafka/jersey-client-2.27.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/common-utils-5.1.0.jar:/usr/bin/../share/java/kafka/kafka-clients-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/netty-3.10.6.Final.jar:/usr/bin/../share/java/kafka/connect-transforms-2.1.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.12.v20180830.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0-b42.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/httpclient-4.5.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.1.0-cp1-sources.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.1.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.14.2.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/confluent-support-metrics/*:/usr/share/java/confluent-support-metrics/* (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,210] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,210] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,210] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,210] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,211] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,211] INFO Client environment:os.version=5.4.0-33-generic (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,211] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,211] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,211] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,213] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@dd05255 (org.apache.zookeeper.ZooKeeper)
[36mkafka            |[0m [2020-06-02 10:39:03,250] INFO Opening socket connection to server zookeeper/172.22.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mkafka            |[0m [2020-06-02 10:39:03,251] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[35mzookeeper        |[0m 2020-06-02 10:39:03,266 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /172.22.0.4:33778
[36mkafka            |[0m [2020-06-02 10:39:03,271] INFO Socket connection established to zookeeper/172.22.0.3:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[35mzookeeper        |[0m 2020-06-02 10:39:03,274 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@928] - Client attempting to establish new session at /172.22.0.4:33778
[35mzookeeper        |[0m 2020-06-02 10:39:03,281 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@673] - Established session 0x172749ccd300001 with negotiated timeout 6000 for client /172.22.0.4:33778
[36mkafka            |[0m [2020-06-02 10:39:03,284] INFO Session establishment complete on server zookeeper/172.22.0.3:2181, sessionid = 0x172749ccd300001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mkafka            |[0m [2020-06-02 10:39:03,288] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[35mzookeeper        |[0m 2020-06-02 10:39:03,392 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x1 zxid:0x4de txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[35mzookeeper        |[0m 2020-06-02 10:39:03,407 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x2 zxid:0x4df txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[35mzookeeper        |[0m 2020-06-02 10:39:03,412 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x3 zxid:0x4e0 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[35mzookeeper        |[0m 2020-06-02 10:39:03,424 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x4 zxid:0x4e1 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[35mzookeeper        |[0m 2020-06-02 10:39:03,433 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x5 zxid:0x4e2 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[35mzookeeper        |[0m 2020-06-02 10:39:03,437 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x6 zxid:0x4e3 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[35mzookeeper        |[0m 2020-06-02 10:39:03,440 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x7 zxid:0x4e4 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[35mzookeeper        |[0m 2020-06-02 10:39:03,444 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x8 zxid:0x4e5 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[35mzookeeper        |[0m 2020-06-02 10:39:03,448 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0x9 zxid:0x4e6 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[35mzookeeper        |[0m 2020-06-02 10:39:03,453 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0xa zxid:0x4e7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[35mzookeeper        |[0m 2020-06-02 10:39:03,457 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0xb zxid:0x4e8 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[35mzookeeper        |[0m 2020-06-02 10:39:03,461 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0xc zxid:0x4e9 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[35mzookeeper        |[0m 2020-06-02 10:39:03,465 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@649] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:create cxid:0xd zxid:0x4ea txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[36mkafka            |[0m [2020-06-02 10:39:03,814] INFO Cluster ID = CaiFW9wnThKVEnKWH302Fw (kafka.server.KafkaServer)
[36mkafka            |[0m [2020-06-02 10:39:03,940] INFO KafkaConfig values: 
[36mkafka            |[0m 	advertised.host.name = null
[36mkafka            |[0m 	advertised.listeners = LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://kafka:9092
[36mkafka            |[0m 	advertised.port = null
[36mkafka            |[0m 	alter.config.policy.class.name = null
[36mkafka            |[0m 	alter.log.dirs.replication.quota.window.num = 11
[36mkafka            |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[36mkafka            |[0m 	authorizer.class.name = 
[36mkafka            |[0m 	auto.create.topics.enable = true
[36mkafka            |[0m 	auto.leader.rebalance.enable = true
[36mkafka            |[0m 	background.threads = 10
[36mkafka            |[0m 	broker.id = 1
[36mkafka            |[0m 	broker.id.generation.enable = true
[36mkafka            |[0m 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
[36mkafka            |[0m 	broker.rack = null
[36mkafka            |[0m 	client.quota.callback.class = null
[36mkafka            |[0m 	compression.type = producer
[36mkafka            |[0m 	connection.failed.authentication.delay.ms = 100
[36mkafka            |[0m 	connections.max.idle.ms = 600000
[36mkafka            |[0m 	controlled.shutdown.enable = true
[36mkafka            |[0m 	controlled.shutdown.max.retries = 3
[36mkafka            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mkafka            |[0m 	controller.socket.timeout.ms = 30000
[36mkafka            |[0m 	create.topic.policy.class.name = null
[36mkafka            |[0m 	default.replication.factor = 1
[36mkafka            |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[36mkafka            |[0m 	delegation.token.expiry.time.ms = 86400000
[36mkafka            |[0m 	delegation.token.master.key = null
[36mkafka            |[0m 	delegation.token.max.lifetime.ms = 604800000
[36mkafka            |[0m 	delete.records.purgatory.purge.interval.requests = 1
[36mkafka            |[0m 	delete.topic.enable = true
[36mkafka            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mkafka            |[0m 	group.initial.rebalance.delay.ms = 3000
[36mkafka            |[0m 	group.max.session.timeout.ms = 300000
[36mkafka            |[0m 	group.min.session.timeout.ms = 6000
[36mkafka            |[0m 	host.name = 
[36mkafka            |[0m 	inter.broker.listener.name = LISTENER_DOCKER_INTERNAL
[36mkafka            |[0m 	inter.broker.protocol.version = 2.1-IV2
[36mkafka            |[0m 	kafka.metrics.polling.interval.secs = 10
[36mkafka            |[0m 	kafka.metrics.reporters = []
[36mkafka            |[0m 	leader.imbalance.check.interval.seconds = 300
[36mkafka            |[0m 	leader.imbalance.per.broker.percentage = 10
[36mkafka            |[0m 	listener.security.protocol.map = LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
[36mkafka            |[0m 	listeners = LISTENER_DOCKER_INTERNAL://0.0.0.0:19092,LISTENER_DOCKER_EXTERNAL://0.0.0.0:9092
[36mkafka            |[0m 	log.cleaner.backoff.ms = 15000
[36mkafka            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mkafka            |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mkafka            |[0m 	log.cleaner.enable = true
[36mkafka            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mkafka            |[0m 	log.cleaner.io.buffer.size = 524288
[36mkafka            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mkafka            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mkafka            |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36mkafka            |[0m 	log.cleaner.threads = 1
[36mkafka            |[0m 	log.cleanup.policy = [delete]
[36mkafka            |[0m 	log.dir = /tmp/kafka-logs
[36mkafka            |[0m 	log.dirs = /var/lib/kafka/data
[36mkafka            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mkafka            |[0m 	log.flush.interval.ms = null
[36mkafka            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mkafka            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mkafka            |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[36mkafka            |[0m 	log.index.interval.bytes = 4096
[36mkafka            |[0m 	log.index.size.max.bytes = 10485760
[36mkafka            |[0m 	log.message.downconversion.enable = true
[36mkafka            |[0m 	log.message.format.version = 2.1-IV2
[36mkafka            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mkafka            |[0m 	log.message.timestamp.type = CreateTime
[36mkafka            |[0m 	log.preallocate = false
[36mkafka            |[0m 	log.retention.bytes = -1
[36mkafka            |[0m 	log.retention.check.interval.ms = 300000
[36mkafka            |[0m 	log.retention.hours = 168
[36mkafka            |[0m 	log.retention.minutes = null
[36mkafka            |[0m 	log.retention.ms = null
[36mkafka            |[0m 	log.roll.hours = 168
[36mkafka            |[0m 	log.roll.jitter.hours = 0
[36mkafka            |[0m 	log.roll.jitter.ms = null
[36mkafka            |[0m 	log.roll.ms = null
[36mkafka            |[0m 	log.segment.bytes = 1073741824
[36mkafka            |[0m 	log.segment.delete.delay.ms = 60000
[36mkafka            |[0m 	max.connections.per.ip = 2147483647
[36mkafka            |[0m 	max.connections.per.ip.overrides = 
[36mkafka            |[0m 	max.incremental.fetch.session.cache.slots = 1000
[36mkafka            |[0m 	message.max.bytes = 1000012
[36mkafka            |[0m 	metric.reporters = []
[36mkafka            |[0m 	metrics.num.samples = 2
[36mkafka            |[0m 	metrics.recording.level = INFO
[36mkafka            |[0m 	metrics.sample.window.ms = 30000
[36mkafka            |[0m 	min.insync.replicas = 1
[36mkafka            |[0m 	num.io.threads = 8
[36mkafka            |[0m 	num.network.threads = 3
[36mkafka            |[0m 	num.partitions = 1
[36mkafka            |[0m 	num.recovery.threads.per.data.dir = 1
[36mkafka            |[0m 	num.replica.alter.log.dirs.threads = null
[36mkafka            |[0m 	num.replica.fetchers = 1
[36mkafka            |[0m 	offset.metadata.max.bytes = 4096
[36mkafka            |[0m 	offsets.commit.required.acks = -1
[36mkafka            |[0m 	offsets.commit.timeout.ms = 5000
[36mkafka            |[0m 	offsets.load.buffer.size = 5242880
[36mkafka            |[0m 	offsets.retention.check.interval.ms = 600000
[36mkafka            |[0m 	offsets.retention.minutes = 10080
[36mkafka            |[0m 	offsets.topic.compression.codec = 0
[36mkafka            |[0m 	offsets.topic.num.partitions = 50
[36mkafka            |[0m 	offsets.topic.replication.factor = 1
[36mkafka            |[0m 	offsets.topic.segment.bytes = 104857600
[36mkafka            |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36mkafka            |[0m 	password.encoder.iterations = 4096
[36mkafka            |[0m 	password.encoder.key.length = 128
[36mkafka            |[0m 	password.encoder.keyfactory.algorithm = null
[36mkafka            |[0m 	password.encoder.old.secret = null
[36mkafka            |[0m 	password.encoder.secret = null
[36mkafka            |[0m 	port = 9092
[36mkafka            |[0m 	principal.builder.class = null
[36mkafka            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mkafka            |[0m 	queued.max.request.bytes = -1
[36mkafka            |[0m 	queued.max.requests = 500
[36mkafka            |[0m 	quota.consumer.default = 9223372036854775807
[36mkafka            |[0m 	quota.producer.default = 9223372036854775807
[36mkafka            |[0m 	quota.window.num = 11
[36mkafka            |[0m 	quota.window.size.seconds = 1
[36mkafka            |[0m 	replica.fetch.backoff.ms = 1000
[36mkafka            |[0m 	replica.fetch.max.bytes = 1048576
[36mkafka            |[0m 	replica.fetch.min.bytes = 1
[36mkafka            |[0m 	replica.fetch.response.max.bytes = 10485760
[36mkafka            |[0m 	replica.fetch.wait.max.ms = 500
[36mkafka            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mkafka            |[0m 	replica.lag.time.max.ms = 10000
[36mkafka            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mkafka            |[0m 	replica.socket.timeout.ms = 30000
[36mkafka            |[0m 	replication.quota.window.num = 11
[36mkafka            |[0m 	replication.quota.window.size.seconds = 1
[36mkafka            |[0m 	request.timeout.ms = 30000
[36mkafka            |[0m 	reserved.broker.max.id = 1000
[36mkafka            |[0m 	sasl.client.callback.handler.class = null
[36mkafka            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mkafka            |[0m 	sasl.jaas.config = null
[36mkafka            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkafka            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mkafka            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mkafka            |[0m 	sasl.kerberos.service.name = null
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.callback.handler.class = null
[36mkafka            |[0m 	sasl.login.class = null
[36mkafka            |[0m 	sasl.login.refresh.buffer.seconds = 300
[36mkafka            |[0m 	sasl.login.refresh.min.period.seconds = 60
[36mkafka            |[0m 	sasl.login.refresh.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.refresh.window.jitter = 0.05
[36mkafka            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mkafka            |[0m 	sasl.server.callback.handler.class = null
[36mkafka            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mkafka            |[0m 	socket.receive.buffer.bytes = 102400
[36mkafka            |[0m 	socket.request.max.bytes = 104857600
[36mkafka            |[0m 	socket.send.buffer.bytes = 102400
[36mkafka            |[0m 	ssl.cipher.suites = []
[36mkafka            |[0m 	ssl.client.auth = none
[36mkafka            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mkafka            |[0m 	ssl.endpoint.identification.algorithm = https
[36mkafka            |[0m 	ssl.key.password = null
[36mkafka            |[0m 	ssl.keymanager.algorithm = SunX509
[36mkafka            |[0m 	ssl.keystore.location = null
[36mkafka            |[0m 	ssl.keystore.password = null
[36mkafka            |[0m 	ssl.keystore.type = JKS
[36mkafka            |[0m 	ssl.protocol = TLS
[36mkafka            |[0m 	ssl.provider = null
[36mkafka            |[0m 	ssl.secure.random.implementation = null
[36mkafka            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mkafka            |[0m 	ssl.truststore.location = null
[36mkafka            |[0m 	ssl.truststore.password = null
[36mkafka            |[0m 	ssl.truststore.type = JKS
[36mkafka            |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[36mkafka            |[0m 	transaction.max.timeout.ms = 900000
[36mkafka            |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[36mkafka            |[0m 	transaction.state.log.load.buffer.size = 5242880
[36mkafka            |[0m 	transaction.state.log.min.isr = 2
[36mkafka            |[0m 	transaction.state.log.num.partitions = 50
[36mkafka            |[0m 	transaction.state.log.replication.factor = 3
[36mkafka            |[0m 	transaction.state.log.segment.bytes = 104857600
[36mkafka            |[0m 	transactional.id.expiration.ms = 604800000
[36mkafka            |[0m 	unclean.leader.election.enable = false
[36mkafka            |[0m 	zookeeper.connect = zookeeper:2181
[36mkafka            |[0m 	zookeeper.connection.timeout.ms = null
[36mkafka            |[0m 	zookeeper.max.in.flight.requests = 10
[36mkafka            |[0m 	zookeeper.session.timeout.ms = 6000
[36mkafka            |[0m 	zookeeper.set.acl = false
[36mkafka            |[0m 	zookeeper.sync.time.ms = 2000
[36mkafka            |[0m  (kafka.server.KafkaConfig)
[36mkafka            |[0m [2020-06-02 10:39:03,954] INFO KafkaConfig values: 
[36mkafka            |[0m 	advertised.host.name = null
[36mkafka            |[0m 	advertised.listeners = LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://kafka:9092
[36mkafka            |[0m 	advertised.port = null
[36mkafka            |[0m 	alter.config.policy.class.name = null
[36mkafka            |[0m 	alter.log.dirs.replication.quota.window.num = 11
[36mkafka            |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[36mkafka            |[0m 	authorizer.class.name = 
[36mkafka            |[0m 	auto.create.topics.enable = true
[36mkafka            |[0m 	auto.leader.rebalance.enable = true
[36mkafka            |[0m 	background.threads = 10
[36mkafka            |[0m 	broker.id = 1
[36mkafka            |[0m 	broker.id.generation.enable = true
[36mkafka            |[0m 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
[36mkafka            |[0m 	broker.rack = null
[36mkafka            |[0m 	client.quota.callback.class = null
[36mkafka            |[0m 	compression.type = producer
[36mkafka            |[0m 	connection.failed.authentication.delay.ms = 100
[36mkafka            |[0m 	connections.max.idle.ms = 600000
[36mkafka            |[0m 	controlled.shutdown.enable = true
[36mkafka            |[0m 	controlled.shutdown.max.retries = 3
[36mkafka            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mkafka            |[0m 	controller.socket.timeout.ms = 30000
[36mkafka            |[0m 	create.topic.policy.class.name = null
[36mkafka            |[0m 	default.replication.factor = 1
[36mkafka            |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[36mkafka            |[0m 	delegation.token.expiry.time.ms = 86400000
[36mkafka            |[0m 	delegation.token.master.key = null
[36mkafka            |[0m 	delegation.token.max.lifetime.ms = 604800000
[36mkafka            |[0m 	delete.records.purgatory.purge.interval.requests = 1
[36mkafka            |[0m 	delete.topic.enable = true
[36mkafka            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mkafka            |[0m 	group.initial.rebalance.delay.ms = 3000
[36mkafka            |[0m 	group.max.session.timeout.ms = 300000
[36mkafka            |[0m 	group.min.session.timeout.ms = 6000
[36mkafka            |[0m 	host.name = 
[36mkafka            |[0m 	inter.broker.listener.name = LISTENER_DOCKER_INTERNAL
[36mkafka            |[0m 	inter.broker.protocol.version = 2.1-IV2
[36mkafka            |[0m 	kafka.metrics.polling.interval.secs = 10
[36mkafka            |[0m 	kafka.metrics.reporters = []
[36mkafka            |[0m 	leader.imbalance.check.interval.seconds = 300
[36mkafka            |[0m 	leader.imbalance.per.broker.percentage = 10
[36mkafka            |[0m 	listener.security.protocol.map = LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
[36mkafka            |[0m 	listeners = LISTENER_DOCKER_INTERNAL://0.0.0.0:19092,LISTENER_DOCKER_EXTERNAL://0.0.0.0:9092
[36mkafka            |[0m 	log.cleaner.backoff.ms = 15000
[36mkafka            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mkafka            |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mkafka            |[0m 	log.cleaner.enable = true
[36mkafka            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mkafka            |[0m 	log.cleaner.io.buffer.size = 524288
[36mkafka            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mkafka            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mkafka            |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36mkafka            |[0m 	log.cleaner.threads = 1
[36mkafka            |[0m 	log.cleanup.policy = [delete]
[36mkafka            |[0m 	log.dir = /tmp/kafka-logs
[36mkafka            |[0m 	log.dirs = /var/lib/kafka/data
[36mkafka            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mkafka            |[0m 	log.flush.interval.ms = null
[36mkafka            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mkafka            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mkafka            |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[36mkafka            |[0m 	log.index.interval.bytes = 4096
[36mkafka            |[0m 	log.index.size.max.bytes = 10485760
[36mkafka            |[0m 	log.message.downconversion.enable = true
[36mkafka            |[0m 	log.message.format.version = 2.1-IV2
[36mkafka            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mkafka            |[0m 	log.message.timestamp.type = CreateTime
[36mkafka            |[0m 	log.preallocate = false
[36mkafka            |[0m 	log.retention.bytes = -1
[36mkafka            |[0m 	log.retention.check.interval.ms = 300000
[36mkafka            |[0m 	log.retention.hours = 168
[36mkafka            |[0m 	log.retention.minutes = null
[36mkafka            |[0m 	log.retention.ms = null
[36mkafka            |[0m 	log.roll.hours = 168
[36mkafka            |[0m 	log.roll.jitter.hours = 0
[36mkafka            |[0m 	log.roll.jitter.ms = null
[36mkafka            |[0m 	log.roll.ms = null
[36mkafka            |[0m 	log.segment.bytes = 1073741824
[36mkafka            |[0m 	log.segment.delete.delay.ms = 60000
[36mkafka            |[0m 	max.connections.per.ip = 2147483647
[36mkafka            |[0m 	max.connections.per.ip.overrides = 
[36mkafka            |[0m 	max.incremental.fetch.session.cache.slots = 1000
[36mkafka            |[0m 	message.max.bytes = 1000012
[36mkafka            |[0m 	metric.reporters = []
[36mkafka            |[0m 	metrics.num.samples = 2
[36mkafka            |[0m 	metrics.recording.level = INFO
[36mkafka            |[0m 	metrics.sample.window.ms = 30000
[36mkafka            |[0m 	min.insync.replicas = 1
[36mkafka            |[0m 	num.io.threads = 8
[36mkafka            |[0m 	num.network.threads = 3
[36mkafka            |[0m 	num.partitions = 1
[36mkafka            |[0m 	num.recovery.threads.per.data.dir = 1
[36mkafka            |[0m 	num.replica.alter.log.dirs.threads = null
[36mkafka            |[0m 	num.replica.fetchers = 1
[36mkafka            |[0m 	offset.metadata.max.bytes = 4096
[36mkafka            |[0m 	offsets.commit.required.acks = -1
[36mkafka            |[0m 	offsets.commit.timeout.ms = 5000
[36mkafka            |[0m 	offsets.load.buffer.size = 5242880
[36mkafka            |[0m 	offsets.retention.check.interval.ms = 600000
[36mkafka            |[0m 	offsets.retention.minutes = 10080
[36mkafka            |[0m 	offsets.topic.compression.codec = 0
[36mkafka            |[0m 	offsets.topic.num.partitions = 50
[36mkafka            |[0m 	offsets.topic.replication.factor = 1
[36mkafka            |[0m 	offsets.topic.segment.bytes = 104857600
[36mkafka            |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36mkafka            |[0m 	password.encoder.iterations = 4096
[36mkafka            |[0m 	password.encoder.key.length = 128
[36mkafka            |[0m 	password.encoder.keyfactory.algorithm = null
[36mkafka            |[0m 	password.encoder.old.secret = null
[36mkafka            |[0m 	password.encoder.secret = null
[36mkafka            |[0m 	port = 9092
[36mkafka            |[0m 	principal.builder.class = null
[36mkafka            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mkafka            |[0m 	queued.max.request.bytes = -1
[36mkafka            |[0m 	queued.max.requests = 500
[36mkafka            |[0m 	quota.consumer.default = 9223372036854775807
[36mkafka            |[0m 	quota.producer.default = 9223372036854775807
[36mkafka            |[0m 	quota.window.num = 11
[36mkafka            |[0m 	quota.window.size.seconds = 1
[36mkafka            |[0m 	replica.fetch.backoff.ms = 1000
[36mkafka            |[0m 	replica.fetch.max.bytes = 1048576
[36mkafka            |[0m 	replica.fetch.min.bytes = 1
[36mkafka            |[0m 	replica.fetch.response.max.bytes = 10485760
[36mkafka            |[0m 	replica.fetch.wait.max.ms = 500
[36mkafka            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mkafka            |[0m 	replica.lag.time.max.ms = 10000
[36mkafka            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mkafka            |[0m 	replica.socket.timeout.ms = 30000
[36mkafka            |[0m 	replication.quota.window.num = 11
[36mkafka            |[0m 	replication.quota.window.size.seconds = 1
[36mkafka            |[0m 	request.timeout.ms = 30000
[36mkafka            |[0m 	reserved.broker.max.id = 1000
[36mkafka            |[0m 	sasl.client.callback.handler.class = null
[36mkafka            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mkafka            |[0m 	sasl.jaas.config = null
[36mkafka            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkafka            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mkafka            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mkafka            |[0m 	sasl.kerberos.service.name = null
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.callback.handler.class = null
[36mkafka            |[0m 	sasl.login.class = null
[36mkafka            |[0m 	sasl.login.refresh.buffer.seconds = 300
[36mkafka            |[0m 	sasl.login.refresh.min.period.seconds = 60
[36mkafka            |[0m 	sasl.login.refresh.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.refresh.window.jitter = 0.05
[36mkafka            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mkafka            |[0m 	sasl.server.callback.handler.class = null
[36mkafka            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mkafka            |[0m 	socket.receive.buffer.bytes = 102400
[36mkafka            |[0m 	socket.request.max.bytes = 104857600
[36mkafka            |[0m 	socket.send.buffer.bytes = 102400
[36mkafka            |[0m 	ssl.cipher.suites = []
[36mkafka            |[0m 	ssl.client.auth = none
[36mkafka            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mkafka            |[0m 	ssl.endpoint.identification.algorithm = https
[36mkafka            |[0m 	ssl.key.password = null
[36mkafka            |[0m 	ssl.keymanager.algorithm = SunX509
[36mkafka            |[0m 	ssl.keystore.location = null
[36mkafka            |[0m 	ssl.keystore.password = null
[36mkafka            |[0m 	ssl.keystore.type = JKS
[36mkafka            |[0m 	ssl.protocol = TLS
[36mkafka            |[0m 	ssl.provider = null
[36mkafka            |[0m 	ssl.secure.random.implementation = null
[36mkafka            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mkafka            |[0m 	ssl.truststore.location = null
[36mkafka            |[0m 	ssl.truststore.password = null
[36mkafka            |[0m 	ssl.truststore.type = JKS
[36mkafka            |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[36mkafka            |[0m 	transaction.max.timeout.ms = 900000
[36mkafka            |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[36mkafka            |[0m 	transaction.state.log.load.buffer.size = 5242880
[36mkafka            |[0m 	transaction.state.log.min.isr = 2
[36mkafka            |[0m 	transaction.state.log.num.partitions = 50
[36mkafka            |[0m 	transaction.state.log.replication.factor = 3
[36mkafka            |[0m 	transaction.state.log.segment.bytes = 104857600
[36mkafka            |[0m 	transactional.id.expiration.ms = 604800000
[36mkafka            |[0m 	unclean.leader.election.enable = false
[36mkafka            |[0m 	zookeeper.connect = zookeeper:2181
[36mkafka            |[0m 	zookeeper.connection.timeout.ms = null
[36mkafka            |[0m 	zookeeper.max.in.flight.requests = 10
[36mkafka            |[0m 	zookeeper.session.timeout.ms = 6000
[36mkafka            |[0m 	zookeeper.set.acl = false
[36mkafka            |[0m 	zookeeper.sync.time.ms = 2000
[36mkafka            |[0m  (kafka.server.KafkaConfig)
[36mkafka            |[0m [2020-06-02 10:39:03,999] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[36mkafka            |[0m [2020-06-02 10:39:04,001] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[36mkafka            |[0m [2020-06-02 10:39:04,006] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[36mkafka            |[0m [2020-06-02 10:39:04,070] INFO Loading logs. (kafka.log.LogManager)
[36mkafka            |[0m [2020-06-02 10:39:04,173] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,188] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,242] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,243] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,295] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,296] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,317] INFO [Log partition=ingredientsReq-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,318] INFO [Log partition=ingredientsReq-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,334] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,335] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,350] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,351] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,371] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,372] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,395] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,395] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,414] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,415] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,426] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,427] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,439] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,440] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,451] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,452] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,465] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,466] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,479] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,479] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,494] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,495] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,514] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,515] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,534] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,534] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,557] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 5492 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,565] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file '/var/lib/kafka/data/__consumer_offsets-9/00000000000000005492.snapshot' (kafka.log.ProducerStateManager)
[36mkafka            |[0m [2020-06-02 10:39:04,578] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Completed load of log with 2 segments, log start offset 0 and log end offset 5492 in 40 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,586] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,587] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,597] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,597] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,610] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,611] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,622] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,623] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,636] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,636] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,655] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,656] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,685] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,687] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,697] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,698] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,707] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,708] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,719] INFO [Log partition=instruments-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,720] INFO [Log partition=instruments-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,742] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,742] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,750] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,751] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,763] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,763] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,783] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,784] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,799] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,800] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,808] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,810] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,820] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,821] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,834] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,835] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,853] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,856] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,867] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,867] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,875] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,876] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,886] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,887] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,895] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,896] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,906] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,906] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,920] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,921] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,932] INFO [Log partition=usersReq-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,933] INFO [Log partition=usersReq-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,943] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,943] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,955] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,956] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,970] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,970] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,987] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,987] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,998] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:04,999] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,007] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,008] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,018] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,019] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,029] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,030] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,039] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,039] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,050] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,050] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:05,053] INFO Logs loading complete in 983 ms. (kafka.log.LogManager)
[36mkafka            |[0m [2020-06-02 10:39:05,065] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[36mkafka            |[0m [2020-06-02 10:39:05,066] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[36mkafka            |[0m [2020-06-02 10:39:05,068] INFO Starting the log cleaner (kafka.log.LogCleaner)
[36mkafka            |[0m [2020-06-02 10:39:05,151] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
[36mkafka            |[0m [2020-06-02 10:39:05,568] INFO Awaiting socket connections on 0.0.0.0:19092. (kafka.network.Acceptor)
[36mkafka            |[0m [2020-06-02 10:39:05,651] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[36mkafka            |[0m [2020-06-02 10:39:05,689] INFO [SocketServer brokerId=1] Started 2 acceptor threads (kafka.network.SocketServer)
[36mkafka            |[0m [2020-06-02 10:39:05,711] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka            |[0m [2020-06-02 10:39:05,712] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka            |[0m [2020-06-02 10:39:05,715] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka            |[0m [2020-06-02 10:39:05,739] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[36mkafka            |[0m [2020-06-02 10:39:05,813] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[36mkafka            |[0m [2020-06-02 10:39:05,836] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[36mkafka            |[0m [2020-06-02 10:39:05,838] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka,19092,ListenerName(LISTENER_DOCKER_INTERNAL),PLAINTEXT), EndPoint(kafka,9092,ListenerName(LISTENER_DOCKER_EXTERNAL),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[36mkafka            |[0m [2020-06-02 10:39:05,939] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka            |[0m [2020-06-02 10:39:05,939] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[36mkafka            |[0m [2020-06-02 10:39:05,960] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka            |[0m [2020-06-02 10:39:05,978] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka            |[0m [2020-06-02 10:39:06,009] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:06,018] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:06,020] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:06,036] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 51 and epoch zk version is now 51 (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,036] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,047] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,052] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,060] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,084] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:50000,blockEndProducerId:50999) by writing to Zk with path version 51 (kafka.coordinator.transaction.ProducerIdManager)
[36mkafka            |[0m [2020-06-02 10:39:06,163] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:06,173] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:06,195] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[36mkafka            |[0m [2020-06-02 10:39:06,313] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
[36mkafka            |[0m [2020-06-02 10:39:06,316] INFO [Controller id=1] Partitions being reassigned: Map() (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,317] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,319] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[36mkafka            |[0m [2020-06-02 10:39:06,323] INFO [Controller id=1] Currently shutting brokers in the cluster: Set() (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,324] INFO [Controller id=1] Current list of topics in the cluster: Set(usersReq, __consumer_offsets, ingredientsReq, __confluent.support.metrics, instruments) (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,325] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,343] WARN [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] retention.ms for topic __confluent.support.metrics is set to 31536000000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[36mkafka            |[0m [2020-06-02 10:39:06,352] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,353] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,354] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,355] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,396] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ReplicaStateMachine)
[36mkafka            |[0m [2020-06-02 10:39:06,413] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ReplicaStateMachine)
[36mkafka            |[0m [2020-06-02 10:39:06,440] INFO [SocketServer brokerId=1] Started processors for 2 acceptors (kafka.network.SocketServer)
[36mkafka            |[0m [2020-06-02 10:39:06,448] INFO Kafka version : 2.1.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)
[36mkafka            |[0m [2020-06-02 10:39:06,471] INFO Kafka commitId : bda8715f42a1a3db (org.apache.kafka.common.utils.AppInfoParser)
[36mkafka            |[0m [2020-06-02 10:39:06,488] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[36mkafka            |[0m [2020-06-02 10:39:06,492] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:19092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[36mkafka            |[0m [2020-06-02 10:39:06,499] INFO Waiting until monitored service is ready for metrics collection (io.confluent.support.metrics.BaseMetricsReporter)
[36mkafka            |[0m [2020-06-02 10:39:06,500] INFO Monitored service is now ready (io.confluent.support.metrics.BaseMetricsReporter)
[36mkafka            |[0m [2020-06-02 10:39:06,501] INFO Attempting to collect and submit metrics (io.confluent.support.metrics.BaseMetricsReporter)
[36mkafka            |[0m [2020-06-02 10:39:06,622] INFO [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__confluent.support.metrics,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=usersReq,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=instruments,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=ingredientsReq,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica) (kafka.controller.ReplicaStateMachine)
[36mkafka            |[0m [2020-06-02 10:39:06,623] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.PartitionStateMachine)
[36mkafka            |[0m [2020-06-02 10:39:06,627] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.PartitionStateMachine)
[36mkafka            |[0m [2020-06-02 10:39:06,631] INFO [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(__consumer_offsets-49 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-13 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, usersReq-0 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, instruments-0 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __confluent.support.metrics-0 -> OnlinePartition, ingredientsReq-0 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition) (kafka.controller.PartitionStateMachine)
[36mkafka            |[0m [2020-06-02 10:39:06,632] INFO [Controller id=1] Ready to serve as the new controller with epoch 51 (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,635] INFO [Controller id=1] Removing partitions Set() from the list of reassigned partitions in zookeeper (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,636] INFO [Controller id=1] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions (kafka.controller.KafkaController)
[35mzookeeper        |[0m 2020-06-02 10:39:06,644 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:multi cxid:0x71 zxid:0x4ee txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
[32muser-service     |[0m [0m[0m2020-06-02 10:39:06,648 INFO  [org.wildfly.swarm.jmx] (main) JMX not configured for remote access
[36mkafka            |[0m [2020-06-02 10:39:06,674] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,679] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,680] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,683] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
[36mkafka            |[0m [2020-06-02 10:39:06,684] INFO [Controller id=1] Starting preferred replica leader election for partitions  (kafka.controller.KafkaController)
[35mzookeeper        |[0m 2020-06-02 10:39:06,688 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x172749ccd300001 type:multi cxid:0x73 zxid:0x4ef txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[36mkafka            |[0m [2020-06-02 10:39:06,711] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:06,805 INFO  [org.wildfly.swarm.datasources] (main) THORN1003: Auto-detected JDBC driver for h2
[32muser-service     |[0m [0m[0m2020-06-02 10:39:06,883 INFO  [org.wildfly.swarm.datasources] (main) THORN1003: Auto-detected JDBC driver for postgresql
[36mkafka            |[0m [2020-06-02 10:39:06,893] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, instruments-0, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, usersReq-0, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, ingredientsReq-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __confluent.support.metrics-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[36mkafka            |[0m [2020-06-02 10:39:06,922] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:06,937] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,001] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,011] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,026] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,031] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,046] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,059] INFO [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,080] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,084] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,107] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,113] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,130] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,134] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,165] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,170] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,194] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,203] INFO [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,222] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,226] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,240] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,247] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,267] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,274] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,333] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,334] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,348] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,352] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,370] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,371] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,385] INFO Replica loaded for partition usersReq-0 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,385] INFO [Partition usersReq-0 broker=1] usersReq-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,402] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,405] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,419] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,420] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,442] WARN The replication factor of topic __confluent.support.metrics is 1, which is less than the desired replication factor of 3.  If you happen to add more brokers to this cluster, then it is important to increase the replication factor of the topic to eventually 3 to ensure reliable and durable metrics collection. (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[36mkafka            |[0m [2020-06-02 10:39:07,452] INFO Replica loaded for partition instruments-0 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,453] INFO [Partition instruments-0 broker=1] instruments-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,490] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,490] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,505] INFO ProducerConfig values: 
[36mkafka            |[0m 	acks = 1
[36mkafka            |[0m 	batch.size = 16384
[36mkafka            |[0m 	bootstrap.servers = []
[36mkafka            |[0m 	buffer.memory = 33554432
[36mkafka            |[0m 	client.dns.lookup = default
[36mkafka            |[0m 	client.id = 
[36mkafka            |[0m 	compression.type = none
[36mkafka            |[0m 	connections.max.idle.ms = 540000
[36mkafka            |[0m 	delivery.timeout.ms = 120000
[36mkafka            |[0m 	enable.idempotence = false
[36mkafka            |[0m 	interceptor.classes = []
[36mkafka            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36mkafka            |[0m 	linger.ms = 0
[36mkafka            |[0m 	max.block.ms = 10000
[36mkafka            |[0m 	max.in.flight.requests.per.connection = 5
[36mkafka            |[0m 	max.request.size = 1048576
[36mkafka            |[0m 	metadata.max.age.ms = 300000
[36mkafka            |[0m 	metric.reporters = []
[36mkafka            |[0m 	metrics.num.samples = 2
[36mkafka            |[0m 	metrics.recording.level = INFO
[36mkafka            |[0m 	metrics.sample.window.ms = 30000
[36mkafka            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36mkafka            |[0m 	receive.buffer.bytes = 32768
[36mkafka            |[0m 	reconnect.backoff.max.ms = 1000
[36mkafka            |[0m 	reconnect.backoff.ms = 50
[36mkafka            |[0m 	request.timeout.ms = 30000
[36mkafka            |[0m 	retries = 2147483647
[36mkafka            |[0m 	retry.backoff.ms = 100
[36mkafka            |[0m 	sasl.client.callback.handler.class = null
[36mkafka            |[0m 	sasl.jaas.config = null
[36mkafka            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkafka            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mkafka            |[0m 	sasl.kerberos.service.name = null
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkafka            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.callback.handler.class = null
[36mkafka            |[0m 	sasl.login.class = null
[36mkafka            |[0m 	sasl.login.refresh.buffer.seconds = 300
[36mkafka            |[0m 	sasl.login.refresh.min.period.seconds = 60
[36mkafka            |[0m 	sasl.login.refresh.window.factor = 0.8
[36mkafka            |[0m 	sasl.login.refresh.window.jitter = 0.05
[36mkafka            |[0m 	sasl.mechanism = GSSAPI
[36mkafka            |[0m 	security.protocol = PLAINTEXT
[36mkafka            |[0m 	send.buffer.bytes = 131072
[36mkafka            |[0m 	ssl.cipher.suites = null
[36mkafka            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mkafka            |[0m 	ssl.endpoint.identification.algorithm = https
[36mkafka            |[0m 	ssl.key.password = null
[36mkafka            |[0m 	ssl.keymanager.algorithm = SunX509
[36mkafka            |[0m 	ssl.keystore.location = null
[36mkafka            |[0m 	ssl.keystore.password = null
[36mkafka            |[0m 	ssl.keystore.type = JKS
[36mkafka            |[0m 	ssl.protocol = TLS
[36mkafka            |[0m 	ssl.provider = null
[36mkafka            |[0m 	ssl.secure.random.implementation = null
[36mkafka            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mkafka            |[0m 	ssl.truststore.location = null
[36mkafka            |[0m 	ssl.truststore.password = null
[36mkafka            |[0m 	ssl.truststore.type = JKS
[36mkafka            |[0m 	transaction.timeout.ms = 60000
[36mkafka            |[0m 	transactional.id = null
[36mkafka            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36mkafka            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36mkafka            |[0m [2020-06-02 10:39:07,525] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,525] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,554] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[36mkafka            |[0m [2020-06-02 10:39:07,564] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,564] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,568] ERROR Could not submit metrics to Kafka topic __confluent.support.metrics: Failed to construct kafka producer (io.confluent.support.metrics.BaseMetricsReporter)
[36mkafka            |[0m [2020-06-02 10:39:07,581] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,581] INFO [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,601] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,602] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,614] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,615] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,628] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,632] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,645] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,647] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,666] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,670] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,689] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,689] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,704] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,705] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,716] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,718] INFO [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,732] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,733] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,752] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,753] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,768] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,771] INFO [Partition __confluent.support.metrics-0 broker=1] __confluent.support.metrics-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,785] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,786] INFO [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,803] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,806] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,814] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,815] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,830] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,831] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,842] INFO Replica loaded for partition ingredientsReq-0 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,843] INFO [Partition ingredientsReq-0 broker=1] ingredientsReq-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,859] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 5492 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,860] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 5492. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,863] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,864] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,871] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,872] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,889] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,890] INFO [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,896] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,897] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,907] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,908] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,918] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,919] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,937] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,938] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,952] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,953] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,972] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,973] INFO [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:07,983] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:07,986] INFO [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:08,002] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:08,003] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:08,017] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:08,019] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:08,033] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:08,036] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:08,045] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[36mkafka            |[0m [2020-06-02 10:39:08,055] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36mkafka            |[0m [2020-06-02 10:39:08,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,076] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,080] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,081] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,082] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,083] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,083] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,086] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,086] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,087] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,087] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,088] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,088] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,089] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,090] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,088] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,096] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,097] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,098] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,098] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,099] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,099] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,100] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,100] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,100] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,102] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,102] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,102] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,102] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,104] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,104] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,106] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,106] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,104] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,107] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,107] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,108] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,108] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,109] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,109] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,110] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,107] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,111] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,127] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,128] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,128] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,129] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,129] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,129] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,130] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,130] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,130] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,130] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,131] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,131] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,131] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,131] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:08,235 INFO  [org.jboss.msc] (main) JBoss MSC version 1.4.11.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:08,266 INFO  [org.jboss.threads] (main) JBoss Threads version 2.3.3.Final
[36mkafka            |[0m [2020-06-02 10:39:08,479] INFO [GroupCoordinator 1]: Loading group metadata for pinfo-microservices with generation 81 (kafka.coordinator.group.GroupCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:08,485] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 352 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,486] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,487] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,488] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,488] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,490] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,491] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,494] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,494] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,494] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,495] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,495] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,495] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka            |[0m [2020-06-02 10:39:08,497] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:08,752 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0049: Thorntail 2.6.0.Final (WildFly Core 10.0.3.Final) starting
[32muser-service     |[0m [0m[0m2020-06-02 10:39:08,846 INFO  [org.wildfly.swarm] (MSC service thread 1-2) THORN0019: Install MSC service for command line args: []
[36mkafka            |[0m [2020-06-02 10:39:10,173] INFO Successfully submitted metrics to Confluent via secure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,355 INFO  [org.wildfly.security] (ServerService Thread Pool -- 3) ELY00001: WildFly Elytron version 1.10.4.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,857 INFO  [org.jboss.as.naming] (ServerService Thread Pool -- 24) WFLYNAM0001: Activating Naming Subsystem
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,876 INFO  [org.jboss.as.naming] (MSC service thread 1-8) WFLYNAM0003: Starting Naming Service
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,910 INFO  [org.jboss.as.jaxrs] (ServerService Thread Pool -- 23) WFLYRS0016: RESTEasy version 3.9.1.Final
[32muser-service     |[0m [0m[33m2020-06-02 10:39:10,915 WARN  [org.jboss.as.txn] (ServerService Thread Pool -- 32) WFLYTX0013: The node-identifier attribute on the /subsystem=transactions is set to the default value. This is a danger for environments running multiple servers. Please make sure the attribute value is unique.
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,923 INFO  [org.jboss.as.clustering.infinispan] (ServerService Thread Pool -- 35) WFLYCLINF0001: Activating Infinispan subsystem.
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,943 INFO  [org.jboss.as.security] (ServerService Thread Pool -- 33) WFLYSEC0002: Activating Security Subsystem
[32muser-service     |[0m [0m[0m2020-06-02 10:39:10,955 INFO  [org.jboss.as.security] (MSC service thread 1-7) WFLYSEC0001: Current PicketBox version=5.0.3.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,057 INFO  [org.jboss.as.connector.subsystems.datasources] (ServerService Thread Pool -- 20) WFLYJCA0004: Deploying JDBC-compliant driver class org.h2.Driver (version 1.4)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,058 INFO  [org.jboss.as.connector] (MSC service thread 1-6) WFLYJCA0009: Starting JCA Subsystem (WildFly/IronJacamar 1.4.17.Final)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,083 INFO  [org.xnio] (ServerService Thread Pool -- 26) XNIO version 3.7.3.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,084 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-8) WFLYJCA0018: Started Driver service with driver-name = myh2
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,099 INFO  [org.jboss.as.connector.subsystems.datasources] (ServerService Thread Pool -- 20) WFLYJCA0005: Deploying non-JDBC-compliant driver class org.postgresql.Driver (version 42.2)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,102 INFO  [org.jboss.as.connector.subsystems.datasources] (ServerService Thread Pool -- 20) WFLYJCA0004: Deploying JDBC-compliant driver class org.h2.Driver (version 1.4)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,103 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-8) WFLYJCA0018: Started Driver service with driver-name = h2
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,111 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-6) WFLYJCA0018: Started Driver service with driver-name = postgresql
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,542 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-5) WFLYUT0003: Undertow 2.0.27.Final starting
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,572 INFO  [org.xnio.nio] (ServerService Thread Pool -- 26) XNIO NIO Implementation Version 3.7.3.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,666 INFO  [org.wildfly.extension.io] (ServerService Thread Pool -- 26) WFLYIO001: Worker 'default' has auto-configured to 8 core threads with 64 task threads based on your 4 available processors
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,855 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-1) WFLYUT0012: Started server default-server.
[32muser-service     |[0m [0m[0m2020-06-02 10:39:11,892 INFO  [org.jboss.remoting] (MSC service thread 1-5) JBoss Remoting version 5.0.15.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:12,027 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-7) WFLYUT0006: Undertow HTTP listener default listening on 0.0.0.0:28080
[32muser-service     |[0m [0m[33m2020-06-02 10:39:12,058 WARN  [org.jboss.as.remoting] (MSC service thread 1-8) ****** All authentication is ANONYMOUS for org.jboss.as.remoting.RemotingHttpUpgradeService
[32muser-service     |[0m [0m[0m2020-06-02 10:39:12,291 INFO  [org.jboss.as.connector.subsystems.datasources] (MSC service thread 1-4) WFLYJCA0001: Bound data source [java:jboss/datasources/auserds]
[32muser-service     |[0m [0m[0m2020-06-02 10:39:12,588 INFO  [org.infinispan.factories.GlobalComponentRegistry] (MSC service thread 1-2) ISPN000128: Infinispan version: Infinispan 'Infinity Minus ONE +2' 9.4.16.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:13,430 INFO  [org.jboss.as.clustering.infinispan] (ServerService Thread Pool -- 38) WFLYCLINF0002: Started passivation cache from web container
[32muser-service     |[0m [0m[0m2020-06-02 10:39:13,427 INFO  [org.jboss.as.clustering.infinispan] (ServerService Thread Pool -- 37) WFLYCLINF0002: Started default cache from server container
[32muser-service     |[0m [0m[0m2020-06-02 10:39:13,707 INFO  [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0212: Resuming server
[32muser-service     |[0m [0m[0m2020-06-02 10:39:13,721 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: Thorntail 2.6.0.Final (WildFly Core 10.0.3.Final) started in 5618ms - Started 255 of 389 services (241 services are lazy, passive or on-demand)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:15,924 INFO  [org.wildfly.swarm.swagger] (main) TTSWGR0004: Configure Swagger for deployment user-service-0.4.0-SNAPSHOT.war with package api.rest
[32muser-service     |[0m [0m[0m2020-06-02 10:39:17,962 INFO  [org.wildfly.swarm.runtime.deployer] (main) deploying user-service-0.4.0-SNAPSHOT.war
[32muser-service     |[0m [0m[0m2020-06-02 10:39:18,027 INFO  [org.jboss.as.server.deployment] (MSC service thread 1-8) WFLYSRV0027: Starting deployment of "user-service-0.4.0-SNAPSHOT.war" (runtime-name: "user-service-0.4.0-SNAPSHOT.war")
[36mkafka            |[0m [2020-06-02 10:39:18,492] INFO [GroupCoordinator 1]: Member consumer-1-381c0ad8-4d4c-4534-8c46-e8a68cc1ccfb in group pinfo-microservices has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:18,494] INFO [GroupCoordinator 1]: Preparing to rebalance group pinfo-microservices in state PreparingRebalance with old generation 81 (__consumer_offsets-9) (reason: removing member consumer-1-381c0ad8-4d4c-4534-8c46-e8a68cc1ccfb on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:18,498] INFO [GroupCoordinator 1]: Group pinfo-microservices with generation 82 is now empty (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,422 INFO  [org.jboss.as.jpa] (MSC service thread 1-4) WFLYJPA0002: Read persistence.xml for AUserPU
[32muser-service     |[0m [0m[33m2020-06-02 10:39:20,539 WARN  [org.jboss.as.dependency.private] (MSC service thread 1-8) WFLYSRV0018: Deployment "deployment.user-service-0.4.0-SNAPSHOT.war" is using a private module ("org.jboss.ironjacamar.jdbcadapters") which may be changed or removed in future versions without notice.
[32muser-service     |[0m [0m[33m2020-06-02 10:39:20,540 WARN  [org.jboss.as.dependency.private] (MSC service thread 1-8) WFLYSRV0018: Deployment "deployment.user-service-0.4.0-SNAPSHOT.war" is using a private module ("org.jboss.jts") which may be changed or removed in future versions without notice.
[32muser-service     |[0m [0m[33m2020-06-02 10:39:20,540 WARN  [org.jboss.as.dependency.private] (MSC service thread 1-8) WFLYSRV0018: Deployment "deployment.user-service-0.4.0-SNAPSHOT.war" is using a private module ("org.infinispan") which may be changed or removed in future versions without notice.
[32muser-service     |[0m [0m[33m2020-06-02 10:39:20,541 WARN  [org.jboss.as.dependency.private] (MSC service thread 1-8) WFLYSRV0018: Deployment "deployment.user-service-0.4.0-SNAPSHOT.war" is using a private module ("org.infinispan.commons") which may be changed or removed in future versions without notice.
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,562 INFO  [org.jboss.as.jpa] (ServerService Thread Pool -- 12) WFLYJPA0010: Starting Persistence Unit (phase 1 of 2) Service 'user-service-0.4.0-SNAPSHOT.war#AUserPU'
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,581 INFO  [org.jboss.weld.deployer] (MSC service thread 1-1) WFLYWELD0003: Processing weld deployment user-service-0.4.0-SNAPSHOT.war
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,590 INFO  [org.hibernate.jpa.internal.util.LogHelper] (ServerService Thread Pool -- 12) HHH000204: Processing PersistenceUnitInfo [
[32muser-service     |[0m 	name: AUserPU
[32muser-service     |[0m 	...]
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,681 INFO  [org.hibernate.Version] (ServerService Thread Pool -- 12) HHH000412: Hibernate Core {5.3.13.Final}
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,683 INFO  [org.hibernate.cfg.Environment] (ServerService Thread Pool -- 12) HHH000206: hibernate.properties not found
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,726 INFO  [org.hibernate.validator.internal.util.Version] (MSC service thread 1-1) HV000001: Hibernate Validator 6.0.18.Final
[32muser-service     |[0m [0m[0m2020-06-02 10:39:20,870 INFO  [org.hibernate.annotations.common.Version] (ServerService Thread Pool -- 12) HCANN000001: Hibernate Commons Annotations {5.0.5.Final}
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,475 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-5) WFLYJCA0004: Deploying JDBC-compliant driver class org.h2.Driver (version 1.4)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,481 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-5) WFLYJCA0005: Deploying non-JDBC-compliant driver class org.postgresql.Driver (version 42.2)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,514 INFO  [org.jboss.weld.Version] (MSC service thread 1-5) WELD-000900: 3.1.2 (Final)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,602 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0018: Host default-host starting
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,621 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-2) WFLYJCA0018: Started Driver service with driver-name = user-service-0.4.0-SNAPSHOT.war_org.h2.Driver_1_4
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,622 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-2) WFLYJCA0018: Started Driver service with driver-name = user-service-0.4.0-SNAPSHOT.war_org.postgresql.Driver_42_2
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,621 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-1) WFLYJCA0018: Started Driver service with driver-name = user-service-0.4.0-SNAPSHOT.war
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,776 INFO  [org.jboss.as.jpa] (ServerService Thread Pool -- 12) WFLYJPA0010: Starting Persistence Unit (phase 2 of 2) Service 'user-service-0.4.0-SNAPSHOT.war#AUserPU'
[32muser-service     |[0m [0m[0m2020-06-02 10:39:22,964 INFO  [org.hibernate.dialect.Dialect] (ServerService Thread Pool -- 12) HHH000400: Using dialect: org.hibernate.dialect.PostgreSQLDialect
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,137 INFO  [org.hibernate.engine.jdbc.env.internal.LobCreatorBuilderImpl] (ServerService Thread Pool -- 12) HHH000424: Disabling contextual LOB creation as createClob() method threw error : java.lang.reflect.InvocationTargetException
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,145 INFO  [org.hibernate.type.BasicTypeRegistry] (ServerService Thread Pool -- 12) HHH000270: Type registration [java.util.UUID] overrides previous : org.hibernate.type.UUIDBinaryType@34a9261e
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,151 INFO  [org.hibernate.envers.boot.internal.EnversServiceImpl] (ServerService Thread Pool -- 12) Envers integration enabled? : true
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,878 INFO  [stdout] (ServerService Thread Pool -- 12) Hibernate: 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,879 INFO  [stdout] (ServerService Thread Pool -- 12)     
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,879 INFO  [stdout] (ServerService Thread Pool -- 12)     drop table if exists AUser cascade
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,895 INFO  [stdout] (ServerService Thread Pool -- 12) Hibernate: 
[33muser-database    |[0m 2020-06-02 10:39:23.896 UTC [86] ERROR:  syntax error at or near "User" at character 27
[33muser-database    |[0m 2020-06-02 10:39:23.896 UTC [86] STATEMENT:  
[33muser-database    |[0m 	    drop table if exists User cascade
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,895 INFO  [stdout] (ServerService Thread Pool -- 12)     
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,895 INFO  [stdout] (ServerService Thread Pool -- 12)     drop table if exists User cascade
[32muser-service     |[0m [0m[33m2020-06-02 10:39:23,898 WARN  [org.hibernate.tool.schema.internal.ExceptionHandlerLoggedImpl] (ServerService Thread Pool -- 12) GenerationTarget encountered exception accepting command : Error executing DDL "
[32muser-service     |[0m     drop table if exists User cascade" via JDBC Statement: org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "
[32muser-service     |[0m     drop table if exists User cascade" via JDBC Statement
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:241)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112)
[32muser-service     |[0m 	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144)
[32muser-service     |[0m 	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72)
[32muser-service     |[0m 	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310)
[32muser-service     |[0m 	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467)
[32muser-service     |[0m 	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939)
[32muser-service     |[0m 	at org.jboss.as.jpa.hibernate5.TwoPhaseBootstrapImpl.build(TwoPhaseBootstrapImpl.java:44)
[32muser-service     |[0m 	at org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1$1.run(PersistenceUnitServiceImpl.java:170)
[32muser-service     |[0m 	at org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1$1.run(PersistenceUnitServiceImpl.java:128)
[32muser-service     |[0m 	at org.wildfly.security.manager.WildFlySecurityManager.doChecked(WildFlySecurityManager.java:658)
[32muser-service     |[0m 	at org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1.run(PersistenceUnitServiceImpl.java:212)
[32muser-service     |[0m 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
[32muser-service     |[0m 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1982)
[32muser-service     |[0m 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1486)
[32muser-service     |[0m 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1377)
[32muser-service     |[0m 	at java.lang.Thread.run(Thread.java:745)
[32muser-service     |[0m 	at org.jboss.threads.JBossThread.run(JBossThread.java:485)
[32muser-service     |[0m Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "User"
[32muser-service     |[0m   Position: 27
[32muser-service     |[0m 	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2440)
[32muser-service     |[0m 	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2183)
[32muser-service     |[0m 	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:308)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:441)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:365)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:307)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:293)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:270)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:266)
[32muser-service     |[0m 	at org.jboss.jca.adapters.jdbc.WrappedStatement.execute(WrappedStatement.java:198)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54)
[32muser-service     |[0m 	... 22 more
[32muser-service     |[0m 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,900 INFO  [stdout] (ServerService Thread Pool -- 12) Hibernate: 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,900 INFO  [stdout] (ServerService Thread Pool -- 12)     
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,900 INFO  [stdout] (ServerService Thread Pool -- 12)     drop sequence if exists USER_SEQ
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,905 INFO  [stdout] (ServerService Thread Pool -- 12) Hibernate: create sequence USER_SEQ start 1 increment 50
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12) Hibernate: 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12)     
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12)     create table AUser (
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12)        id int8 not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12)         email varchar(255) not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12)         name varchar(255) not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,912 INFO  [stdout] (ServerService Thread Pool -- 12)         ratingDenum int4 not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,913 INFO  [stdout] (ServerService Thread Pool -- 12)         ratingNum int4 not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,913 INFO  [stdout] (ServerService Thread Pool -- 12)         registerDate timestamp not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,913 INFO  [stdout] (ServerService Thread Pool -- 12)         primary key (id)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,913 INFO  [stdout] (ServerService Thread Pool -- 12)     )
[33muser-database    |[0m 2020-06-02 10:39:23.932 UTC [86] ERROR:  syntax error at or near "User" at character 19
[33muser-database    |[0m 2020-06-02 10:39:23.932 UTC [86] STATEMENT:  
[33muser-database    |[0m 	    create table User (
[33muser-database    |[0m 	       id int8 not null,
[33muser-database    |[0m 	        email varchar(255) not null,
[33muser-database    |[0m 	        name varchar(255) not null,
[33muser-database    |[0m 	        ratingDenum int4 not null,
[33muser-database    |[0m 	        ratingNum int4 not null,
[33muser-database    |[0m 	        registerDate timestamp not null,
[33muser-database    |[0m 	        primary key (id)
[33muser-database    |[0m 	    )
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,930 INFO  [stdout] (ServerService Thread Pool -- 12) Hibernate: 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,930 INFO  [stdout] (ServerService Thread Pool -- 12)     
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,930 INFO  [stdout] (ServerService Thread Pool -- 12)     create table User (
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,930 INFO  [stdout] (ServerService Thread Pool -- 12)        id int8 not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,930 INFO  [stdout] (ServerService Thread Pool -- 12)         email varchar(255) not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,931 INFO  [stdout] (ServerService Thread Pool -- 12)         name varchar(255) not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,931 INFO  [stdout] (ServerService Thread Pool -- 12)         ratingDenum int4 not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,931 INFO  [stdout] (ServerService Thread Pool -- 12)         ratingNum int4 not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,931 INFO  [stdout] (ServerService Thread Pool -- 12)         registerDate timestamp not null,
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,931 INFO  [stdout] (ServerService Thread Pool -- 12)         primary key (id)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,931 INFO  [stdout] (ServerService Thread Pool -- 12)     )
[32muser-service     |[0m [0m[33m2020-06-02 10:39:23,932 WARN  [org.hibernate.tool.schema.internal.ExceptionHandlerLoggedImpl] (ServerService Thread Pool -- 12) GenerationTarget encountered exception accepting command : Error executing DDL "
[32muser-service     |[0m     create table User (
[32muser-service     |[0m        id int8 not null,
[32muser-service     |[0m         email varchar(255) not null,
[32muser-service     |[0m         name varchar(255) not null,
[32muser-service     |[0m         ratingDenum int4 not null,
[32muser-service     |[0m         ratingNum int4 not null,
[32muser-service     |[0m         registerDate timestamp not null,
[32muser-service     |[0m         primary key (id)
[32muser-service     |[0m     )" via JDBC Statement: org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "
[32muser-service     |[0m     create table User (
[32muser-service     |[0m        id int8 not null,
[32muser-service     |[0m         email varchar(255) not null,
[32muser-service     |[0m         name varchar(255) not null,
[32muser-service     |[0m         ratingDenum int4 not null,
[32muser-service     |[0m         ratingNum int4 not null,
[32muser-service     |[0m         registerDate timestamp not null,
[32muser-service     |[0m         primary key (id)
[32muser-service     |[0m     )" via JDBC Statement
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlString(SchemaCreatorImpl.java:440)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlStrings(SchemaCreatorImpl.java:424)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.createFromMetadata(SchemaCreatorImpl.java:315)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.performCreation(SchemaCreatorImpl.java:166)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:135)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:121)
[32muser-service     |[0m 	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:155)
[32muser-service     |[0m 	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72)
[32muser-service     |[0m 	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310)
[32muser-service     |[0m 	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467)
[32muser-service     |[0m 	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939)
[32muser-service     |[0m 	at org.jboss.as.jpa.hibernate5.TwoPhaseBootstrapImpl.build(TwoPhaseBootstrapImpl.java:44)
[32muser-service     |[0m 	at org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1$1.run(PersistenceUnitServiceImpl.java:170)
[32muser-service     |[0m 	at org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1$1.run(PersistenceUnitServiceImpl.java:128)
[32muser-service     |[0m 	at org.wildfly.security.manager.WildFlySecurityManager.doChecked(WildFlySecurityManager.java:658)
[32muser-service     |[0m 	at org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1.run(PersistenceUnitServiceImpl.java:212)
[32muser-service     |[0m 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)
[32muser-service     |[0m 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1982)
[32muser-service     |[0m 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1486)
[32muser-service     |[0m 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1377)
[32muser-service     |[0m 	at java.lang.Thread.run(Thread.java:745)
[32muser-service     |[0m 	at org.jboss.threads.JBossThread.run(JBossThread.java:485)
[32muser-service     |[0m Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near "User"
[32muser-service     |[0m   Position: 19
[32muser-service     |[0m 	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2440)
[32muser-service     |[0m 	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2183)
[32muser-service     |[0m 	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:308)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:441)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:365)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:307)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:293)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:270)
[32muser-service     |[0m 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:266)
[32muser-service     |[0m 	at org.jboss.jca.adapters.jdbc.WrappedStatement.execute(WrappedStatement.java:198)
[32muser-service     |[0m 	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54)
[32muser-service     |[0m 	... 22 more
[32muser-service     |[0m 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:23,941 INFO  [org.hibernate.tool.schema.internal.SchemaCreatorImpl] (ServerService Thread Pool -- 12) HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@4dce1d6e'
[32muser-service     |[0m [0m[0m2020-06-02 10:39:24,298 INFO  [org.aerogear.kafka.cdi.extension.KafkaExtension] (MSC service thread 1-2) setting bootstrap.servers IP for, #{thorntail.kafka-configuration.host}:#{thorntail.kafka-configuration.port}
[32muser-service     |[0m [0m[0m2020-06-02 10:39:24,751 INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] (MSC service thread 1-2) ConsumerConfig values: 
[32muser-service     |[0m 	auto.commit.interval.ms = 5000
[32muser-service     |[0m 	auto.offset.reset = latest
[32muser-service     |[0m 	bootstrap.servers = [kafka:9092]
[32muser-service     |[0m 	check.crcs = true
[32muser-service     |[0m 	client.id = 
[32muser-service     |[0m 	connections.max.idle.ms = 540000
[32muser-service     |[0m 	enable.auto.commit = true
[32muser-service     |[0m 	exclude.internal.topics = true
[32muser-service     |[0m 	fetch.max.bytes = 52428800
[32muser-service     |[0m 	fetch.max.wait.ms = 500
[32muser-service     |[0m 	fetch.min.bytes = 1
[32muser-service     |[0m 	group.id = pinfo-microservices
[32muser-service     |[0m 	heartbeat.interval.ms = 3000
[32muser-service     |[0m 	interceptor.classes = null
[32muser-service     |[0m 	internal.leave.group.on.close = true
[32muser-service     |[0m 	isolation.level = read_uncommitted
[32muser-service     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[32muser-service     |[0m 	max.partition.fetch.bytes = 1048576
[32muser-service     |[0m 	max.poll.interval.ms = 300000
[32muser-service     |[0m 	max.poll.records = 500
[32muser-service     |[0m 	metadata.max.age.ms = 300000
[32muser-service     |[0m 	metric.reporters = []
[32muser-service     |[0m 	metrics.num.samples = 2
[32muser-service     |[0m 	metrics.recording.level = INFO
[32muser-service     |[0m 	metrics.sample.window.ms = 30000
[32muser-service     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[32muser-service     |[0m 	receive.buffer.bytes = 65536
[32muser-service     |[0m 	reconnect.backoff.max.ms = 1000
[32muser-service     |[0m 	reconnect.backoff.ms = 50
[32muser-service     |[0m 	request.timeout.ms = 305000
[32muser-service     |[0m 	retry.backoff.ms = 100
[32muser-service     |[0m 	sasl.jaas.config = null
[32muser-service     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32muser-service     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32muser-service     |[0m 	sasl.kerberos.service.name = null
[32muser-service     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32muser-service     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32muser-service     |[0m 	sasl.mechanism = GSSAPI
[32muser-service     |[0m 	security.protocol = PLAINTEXT
[32muser-service     |[0m 	send.buffer.bytes = 131072
[32muser-service     |[0m 	session.timeout.ms = 10000
[32muser-service     |[0m 	ssl.cipher.suites = null
[32muser-service     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32muser-service     |[0m 	ssl.endpoint.identification.algorithm = null
[32muser-service     |[0m 	ssl.key.password = null
[32muser-service     |[0m 	ssl.keymanager.algorithm = SunX509
[32muser-service     |[0m 	ssl.keystore.location = null
[32muser-service     |[0m 	ssl.keystore.password = null
[32muser-service     |[0m 	ssl.keystore.type = JKS
[32muser-service     |[0m 	ssl.protocol = TLS
[32muser-service     |[0m 	ssl.provider = null
[32muser-service     |[0m 	ssl.secure.random.implementation = null
[32muser-service     |[0m 	ssl.trustmanager.algorithm = PKIX
[32muser-service     |[0m 	ssl.truststore.location = null
[32muser-service     |[0m 	ssl.truststore.password = null
[32muser-service     |[0m 	ssl.truststore.type = JKS
[32muser-service     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[32muser-service     |[0m 
[32muser-service     |[0m [0m[0m2020-06-02 10:39:24,817 INFO  [org.apache.kafka.common.utils.AppInfoParser] (MSC service thread 1-2) Kafka version : 1.0.0
[32muser-service     |[0m [0m[0m2020-06-02 10:39:24,817 INFO  [org.apache.kafka.common.utils.AppInfoParser] (MSC service thread 1-2) Kafka commitId : aaa7af6d4a11b29d
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,079 INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] (EE-ManagedExecutorService-default-Thread-1) [Consumer clientId=consumer-1, groupId=pinfo-microservices] Discovered coordinator kafka:9092 (id: 2147483646 rack: null)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,082 INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] (EE-ManagedExecutorService-default-Thread-1) [Consumer clientId=consumer-1, groupId=pinfo-microservices] Revoking previously assigned partitions []
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,083 INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] (EE-ManagedExecutorService-default-Thread-1) [Consumer clientId=consumer-1, groupId=pinfo-microservices] (Re-)joining group
[36mkafka            |[0m [2020-06-02 10:39:25,094] INFO [GroupCoordinator 1]: Preparing to rebalance group pinfo-microservices in state PreparingRebalance with old generation 82 (__consumer_offsets-9) (reason: Adding new member consumer-1-c92d9cbd-bafe-4375-8b91-2aee9b4630aa) (kafka.coordinator.group.GroupCoordinator)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,227 INFO  [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 12) RESTEASY002225: Deploying javax.ws.rs.core.Application: class api.rest.JaxRsActivator
[32muser-service     |[0m [0m[33m2020-06-02 10:39:25,228 WARN  [org.jboss.as.weld] (ServerService Thread Pool -- 12) WFLYWELD0052: Using deployment classloader to load proxy classes for module io.swagger. Package-private access will not work. To fix this the module should declare dependencies on [org.jboss.weld.core, org.jboss.weld.spi, org.jboss.weld.api]
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,282 INFO  [org.wildfly.extension.undertow] (ServerService Thread Pool -- 12) WFLYUT0021: Registered web context: '/' for server 'default-server'
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,340 INFO  [org.jboss.as.server] (main) WFLYSRV0010: Deployed "user-service-0.4.0-SNAPSHOT.war" (runtime-name : "user-service-0.4.0-SNAPSHOT.war")
[32muser-service     |[0m [0m[0m2020-06-02 10:39:25,355 INFO  [org.wildfly.swarm] (main) THORN99999: Thorntail is Ready
[36mkafka            |[0m [2020-06-02 10:39:28,107] INFO [GroupCoordinator 1]: Stabilized group pinfo-microservices generation 83 (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[36mkafka            |[0m [2020-06-02 10:39:28,121] INFO [GroupCoordinator 1]: Assignment received from leader for group pinfo-microservices for generation 83 (kafka.coordinator.group.GroupCoordinator)
[32muser-service     |[0m [0m[0m2020-06-02 10:39:28,135 INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] (EE-ManagedExecutorService-default-Thread-1) [Consumer clientId=consumer-1, groupId=pinfo-microservices] Successfully joined group with generation 83
[32muser-service     |[0m [0m[0m2020-06-02 10:39:28,140 INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] (EE-ManagedExecutorService-default-Thread-1) [Consumer clientId=consumer-1, groupId=pinfo-microservices] Setting newly assigned partitions [usersReq-0]
Stopping user-service  ... 
Stopping kafka         ... 
Stopping zookeeper     ... 
Stopping user-database ... 
[4A[2KStopping user-service  ... [32mdone[0m[4B[1A[2KStopping user-database ... [32mdone[0m[1B[3A[2KStopping kafka         ... [32mdone[0m[3B[2A[2KStopping zookeeper     ... [32mdone[0m[2BGracefully stopping... (press Ctrl+C again to force)
